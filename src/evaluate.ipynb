{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.models.yolo.detect.val import DetectionValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = dict(\n",
    "    model = \"/icislab/volume3/benderick/futurama/YOLO-UAV/logs/YOLO-UAV/runs/2025-05-24_11-03-11-MBFD/YOLO-UAV/MBFD/weights/best.pt\",\n",
    "    data = \"/icislab/volume3/benderick/futurama/YOLO-UAV/data/VisDrone/VisDrone.yaml\",\n",
    "    conf=0.001,\n",
    "    batch=16,\n",
    "    device=\"cuda:1\",\n",
    "    save_json=True,\n",
    "    split='test'\n",
    "    )\n",
    "\n",
    "save_dir = Path(\"./logs/val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "validator = DetectionValidator(save_dir=save_dir, args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.88 ğŸš€ Python-3.10.16 torch-2.6.0+cu118 CUDA:1 (NVIDIA GeForce RTX 3090, 24260MiB)\n",
      "MBFD summary: 169 layers, 2,733,694 parameters, 0 gradients, 7.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ”” val: Scanning /icislab/volume3/benderick/futurama/data/VisDrone/VisDrone2019-DET-test-dev/labels.cache... 1610 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1610/1610 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   2%|â–         | 2/101 [00:01<01:41,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 2.800s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   3%|â–         | 3/101 [00:06<03:59,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 2.800s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:44<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1610      75102      0.338      0.258      0.233      0.127\n",
      "            pedestrian       1197      21006      0.354      0.191      0.177     0.0665\n",
      "                people        797       6376       0.35     0.0874      0.102     0.0327\n",
      "               bicycle        377       1302      0.233     0.0238     0.0501     0.0192\n",
      "                   car       1530      28074      0.531      0.674      0.637      0.384\n",
      "                   van       1168       5771       0.28      0.379      0.283      0.176\n",
      "                 truck        750       2659      0.335      0.289      0.245      0.142\n",
      "              tricycle        245        530      0.223      0.132      0.103     0.0538\n",
      "       awning-tricycle        233        599      0.312     0.0935      0.107     0.0561\n",
      "                   bus        838       2940       0.43       0.45      0.423      0.267\n",
      "                 motor        794       5845      0.331      0.264      0.204     0.0768\n",
      "Speed: 0.3ms preprocess, 3.7ms inference, 0.0ms loss, 6.3ms postprocess per image\n",
      "ğŸ”” Using pycocotools:\n",
      "Saving val_pred_coco.json\n",
      "Evaluating pycocotools mAP using logs/val/val_pred_coco.json and /icislab/volume3/benderick/futurama/YOLO-UAV/data/VisDrone/annotations/val_coco.json\n",
      "pycocotools unable to run: /icislab/volume3/benderick/futurama/YOLO-UAV/data/VisDrone/annotations/val_coco.json file not found\n",
      "Results saved to ğŸ”” logs/val\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'metrics/precision(B)': np.float64(0.3380169706160433),\n",
       " 'metrics/recall(B)': np.float64(0.25845219751875137),\n",
       " 'metrics/mAP50(B)': np.float64(0.23300004672371316),\n",
       " 'metrics/mAP50-95(B)': np.float64(0.127458908931889),\n",
       " 'fitness': np.float64(0.1380130227110714)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import numpy as np\n",
    "from prettytable import PrettyTable\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils.torch_utils import model_info\n",
    "\n",
    "# BILIBILI UP é­”å‚€é¢å…·\n",
    "# éªŒè¯å‚æ•°å®˜æ–¹è¯¦è§£é“¾æ¥ï¼šhttps://docs.ultralytics.com/modes/val/#usage-examples:~:text=of%20each%20category-,Arguments%20for%20YOLO%20Model%20Validation,-When%20validating%20YOLO\n",
    "\n",
    "# ç²¾åº¦å°æ•°ç‚¹ä¿ç•™ä½æ•°ä¿®æ”¹é—®é¢˜å¯çœ‹<ä½¿ç”¨è¯´æ˜.md>ä¸‹æ–¹çš„<YOLOV8æºç å¸¸è§ç–‘é—®è§£ç­”å°è¯¾å ‚>ç¬¬äº”ç‚¹\n",
    "# æœ€ç»ˆè®ºæ–‡çš„å‚æ•°é‡å’Œè®¡ç®—é‡ç»Ÿä¸€ä»¥è¿™ä¸ªè„šæœ¬è¿è¡Œå‡ºæ¥çš„ä¸ºå‡†\n",
    "\n",
    "def get_weight_size(path):\n",
    "    stats = os.stat(path)\n",
    "    return f'{stats.st_size / 1024 / 1024:.1f}'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model_path = 'runs/train/exp/weights/best.pt'\n",
    "    model = YOLO(model_path) # é€‰æ‹©è®­ç»ƒå¥½çš„æƒé‡è·¯å¾„\n",
    "    result = model.val(data='/root/dataset/dataset_visdrone/data.yaml',\n",
    "                        split='val', # splitå¯ä»¥é€‰æ‹©trainã€valã€test æ ¹æ®è‡ªå·±çš„æ•°æ®é›†æƒ…å†µæ¥é€‰æ‹©.\n",
    "                        imgsz=640,\n",
    "                        batch=16,\n",
    "                        # iou=0.7,\n",
    "                        # rect=False,\n",
    "                        # save_json=True, # if you need to cal coco metrice\n",
    "                        project='runs/val',\n",
    "                        name='exp',\n",
    "                        )\n",
    "    \n",
    "    if model.task == 'detect': # ä»…ç›®æ ‡æ£€æµ‹ä»»åŠ¡é€‚ç”¨\n",
    "        model_names = list(result.names.values())\n",
    "        preprocess_time_per_image = result.speed['preprocess']\n",
    "        inference_time_per_image = result.speed['inference']\n",
    "        postprocess_time_per_image = result.speed['postprocess']\n",
    "        all_time_per_image = preprocess_time_per_image + inference_time_per_image + postprocess_time_per_image\n",
    "        \n",
    "        n_l, n_p, n_g, flops = model_info(model.model)\n",
    "        \n",
    "        print('-'*20 + 'è®ºæ–‡ä¸Šçš„æ•°æ®ä»¥ä»¥ä¸‹ç»“æœä¸ºå‡†' + '-'*20)\n",
    "        print('-'*20 + 'è®ºæ–‡ä¸Šçš„æ•°æ®ä»¥ä»¥ä¸‹ç»“æœä¸ºå‡†' + '-'*20)\n",
    "        print('-'*20 + 'è®ºæ–‡ä¸Šçš„æ•°æ®ä»¥ä»¥ä¸‹ç»“æœä¸ºå‡†' + '-'*20)\n",
    "        print('-'*20 + 'è®ºæ–‡ä¸Šçš„æ•°æ®ä»¥ä»¥ä¸‹ç»“æœä¸ºå‡†' + '-'*20)\n",
    "        print('-'*20 + 'è®ºæ–‡ä¸Šçš„æ•°æ®ä»¥ä»¥ä¸‹ç»“æœä¸ºå‡†' + '-'*20)\n",
    "\n",
    "        model_info_table = PrettyTable()\n",
    "        model_info_table.title = \"Model Info\"\n",
    "        model_info_table.field_names = [\"GFLOPs\", \"Parameters\", \"å‰å¤„ç†æ—¶é—´/ä¸€å¼ å›¾\", \"æ¨ç†æ—¶é—´/ä¸€å¼ å›¾\", \"åå¤„ç†æ—¶é—´/ä¸€å¼ å›¾\", \"FPS(å‰å¤„ç†+æ¨¡å‹æ¨ç†+åå¤„ç†)\", \"FPS(æ¨ç†)\", \"Model File Size\"]\n",
    "        model_info_table.add_row([f'{flops:.1f}', f'{n_p:,}', \n",
    "                                  f'{preprocess_time_per_image / 1000:.6f}s', f'{inference_time_per_image / 1000:.6f}s', \n",
    "                                  f'{postprocess_time_per_image / 1000:.6f}s', f'{1000 / all_time_per_image:.2f}', \n",
    "                                  f'{1000 / inference_time_per_image:.2f}', f'{get_weight_size(model_path)}MB'])\n",
    "        print(model_info_table)\n",
    "\n",
    "        model_metrice_table = PrettyTable()\n",
    "        model_metrice_table.title = \"Model Metrice\"\n",
    "        model_metrice_table.field_names = [\"Class Name\", \"Precision\", \"Recall\", \"F1-Score\", \"mAP50\", \"mAP75\", \"mAP50-95\"]\n",
    "        for idx, cls_name in enumerate(model_names):\n",
    "            model_metrice_table.add_row([\n",
    "                                        cls_name, \n",
    "                                        f\"{result.box.p[idx]:.4f}\", \n",
    "                                        f\"{result.box.r[idx]:.4f}\", \n",
    "                                        f\"{result.box.f1[idx]:.4f}\", \n",
    "                                        f\"{result.box.ap50[idx]:.4f}\", \n",
    "                                        f\"{result.box.all_ap[idx, 5]:.4f}\", # 50 55 60 65 70 75 80 85 90 95 \n",
    "                                        f\"{result.box.ap[idx]:.4f}\"\n",
    "                                    ])\n",
    "        model_metrice_table.add_row([\n",
    "                                    \"all(å¹³å‡æ•°æ®)\", \n",
    "                                    f\"{result.results_dict['metrics/precision(B)']:.4f}\", \n",
    "                                    f\"{result.results_dict['metrics/recall(B)']:.4f}\", \n",
    "                                    f\"{np.mean(result.box.f1):.4f}\", \n",
    "                                    f\"{result.results_dict['metrics/mAP50(B)']:.4f}\", \n",
    "                                    f\"{np.mean(result.box.all_ap[:, 5]):.4f}\", # 50 55 60 65 70 75 80 85 90 95 \n",
    "                                    f\"{result.results_dict['metrics/mAP50-95(B)']:.4f}\"\n",
    "                                ])\n",
    "        print(model_metrice_table)\n",
    "\n",
    "        with open(result.save_dir / 'paper_data.txt', 'w+') as f:\n",
    "            f.write(str(model_info_table))\n",
    "            f.write('\\n')\n",
    "            f.write(str(model_metrice_table))\n",
    "        \n",
    "        print('-'*20, f'ç»“æœå·²ä¿å­˜è‡³{result.save_dir}/paper_data.txt...', '-'*20)\n",
    "        print('-'*20, f'ç»“æœå·²ä¿å­˜è‡³{result.save_dir}/paper_data.txt...', '-'*20)\n",
    "        print('-'*20, f'ç»“æœå·²ä¿å­˜è‡³{result.save_dir}/paper_data.txt...', '-'*20)\n",
    "        print('-'*20, f'ç»“æœå·²ä¿å­˜è‡³{result.save_dir}/paper_data.txt...', '-'*20)\n",
    "        print('-'*20, f'ç»“æœå·²ä¿å­˜è‡³{result.save_dir}/paper_data.txt...', '-'*20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
