{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.models.yolo.detect.val import DetectionValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"/icislab/volume3/benderick/futurama/YOLO-UAV/configs/model/artifact-1/TMSAB-P2.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= torch.load(\"/icislab/volume3/benderick/futurama/YOLO-UAV/logs/YOLO-UAV/runs/2025-04-26_20-50-48-TMSAB-P2/YOLO-UAV/TMSAB-P2/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = dict(\n",
    "    model = \"./tmp/best.pt\",\n",
    "    data = \"/home/futurama/zhangshuo/YOLO-UAV/data/VisDrone/VisDrone.yaml\",\n",
    "    conf=0.001,\n",
    "    batch=16,\n",
    "    device=\"cuda:1\",\n",
    "    save_json=False\n",
    "    )\n",
    "\n",
    "save_dir = Path(\"./logs/val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validator = DetectionValidator(save_dir=save_dir, args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import numpy as np\n",
    "from prettytable import PrettyTable\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils.torch_utils import model_info\n",
    "\n",
    "# BILIBILI UP 魔傀面具\n",
    "# 验证参数官方详解链接：https://docs.ultralytics.com/modes/val/#usage-examples:~:text=of%20each%20category-,Arguments%20for%20YOLO%20Model%20Validation,-When%20validating%20YOLO\n",
    "\n",
    "# 精度小数点保留位数修改问题可看<使用说明.md>下方的<YOLOV8源码常见疑问解答小课堂>第五点\n",
    "# 最终论文的参数量和计算量统一以这个脚本运行出来的为准\n",
    "\n",
    "def get_weight_size(path):\n",
    "    stats = os.stat(path)\n",
    "    return f'{stats.st_size / 1024 / 1024:.1f}'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model_path = 'runs/train/exp/weights/best.pt'\n",
    "    model = YOLO(model_path) # 选择训练好的权重路径\n",
    "    result = model.val(data='/root/dataset/dataset_visdrone/data.yaml',\n",
    "                        split='val', # split可以选择train、val、test 根据自己的数据集情况来选择.\n",
    "                        imgsz=640,\n",
    "                        batch=16,\n",
    "                        # iou=0.7,\n",
    "                        # rect=False,\n",
    "                        # save_json=True, # if you need to cal coco metrice\n",
    "                        project='runs/val',\n",
    "                        name='exp',\n",
    "                        )\n",
    "    \n",
    "    if model.task == 'detect': # 仅目标检测任务适用\n",
    "        model_names = list(result.names.values())\n",
    "        preprocess_time_per_image = result.speed['preprocess']\n",
    "        inference_time_per_image = result.speed['inference']\n",
    "        postprocess_time_per_image = result.speed['postprocess']\n",
    "        all_time_per_image = preprocess_time_per_image + inference_time_per_image + postprocess_time_per_image\n",
    "        \n",
    "        n_l, n_p, n_g, flops = model_info(model.model)\n",
    "        \n",
    "        print('-'*20 + '论文上的数据以以下结果为准' + '-'*20)\n",
    "        print('-'*20 + '论文上的数据以以下结果为准' + '-'*20)\n",
    "        print('-'*20 + '论文上的数据以以下结果为准' + '-'*20)\n",
    "        print('-'*20 + '论文上的数据以以下结果为准' + '-'*20)\n",
    "        print('-'*20 + '论文上的数据以以下结果为准' + '-'*20)\n",
    "\n",
    "        model_info_table = PrettyTable()\n",
    "        model_info_table.title = \"Model Info\"\n",
    "        model_info_table.field_names = [\"GFLOPs\", \"Parameters\", \"前处理时间/一张图\", \"推理时间/一张图\", \"后处理时间/一张图\", \"FPS(前处理+模型推理+后处理)\", \"FPS(推理)\", \"Model File Size\"]\n",
    "        model_info_table.add_row([f'{flops:.1f}', f'{n_p:,}', \n",
    "                                  f'{preprocess_time_per_image / 1000:.6f}s', f'{inference_time_per_image / 1000:.6f}s', \n",
    "                                  f'{postprocess_time_per_image / 1000:.6f}s', f'{1000 / all_time_per_image:.2f}', \n",
    "                                  f'{1000 / inference_time_per_image:.2f}', f'{get_weight_size(model_path)}MB'])\n",
    "        print(model_info_table)\n",
    "\n",
    "        model_metrice_table = PrettyTable()\n",
    "        model_metrice_table.title = \"Model Metrice\"\n",
    "        model_metrice_table.field_names = [\"Class Name\", \"Precision\", \"Recall\", \"F1-Score\", \"mAP50\", \"mAP75\", \"mAP50-95\"]\n",
    "        for idx, cls_name in enumerate(model_names):\n",
    "            model_metrice_table.add_row([\n",
    "                                        cls_name, \n",
    "                                        f\"{result.box.p[idx]:.4f}\", \n",
    "                                        f\"{result.box.r[idx]:.4f}\", \n",
    "                                        f\"{result.box.f1[idx]:.4f}\", \n",
    "                                        f\"{result.box.ap50[idx]:.4f}\", \n",
    "                                        f\"{result.box.all_ap[idx, 5]:.4f}\", # 50 55 60 65 70 75 80 85 90 95 \n",
    "                                        f\"{result.box.ap[idx]:.4f}\"\n",
    "                                    ])\n",
    "        model_metrice_table.add_row([\n",
    "                                    \"all(平均数据)\", \n",
    "                                    f\"{result.results_dict['metrics/precision(B)']:.4f}\", \n",
    "                                    f\"{result.results_dict['metrics/recall(B)']:.4f}\", \n",
    "                                    f\"{np.mean(result.box.f1):.4f}\", \n",
    "                                    f\"{result.results_dict['metrics/mAP50(B)']:.4f}\", \n",
    "                                    f\"{np.mean(result.box.all_ap[:, 5]):.4f}\", # 50 55 60 65 70 75 80 85 90 95 \n",
    "                                    f\"{result.results_dict['metrics/mAP50-95(B)']:.4f}\"\n",
    "                                ])\n",
    "        print(model_metrice_table)\n",
    "\n",
    "        with open(result.save_dir / 'paper_data.txt', 'w+') as f:\n",
    "            f.write(str(model_info_table))\n",
    "            f.write('\\n')\n",
    "            f.write(str(model_metrice_table))\n",
    "        \n",
    "        print('-'*20, f'结果已保存至{result.save_dir}/paper_data.txt...', '-'*20)\n",
    "        print('-'*20, f'结果已保存至{result.save_dir}/paper_data.txt...', '-'*20)\n",
    "        print('-'*20, f'结果已保存至{result.save_dir}/paper_data.txt...', '-'*20)\n",
    "        print('-'*20, f'结果已保存至{result.save_dir}/paper_data.txt...', '-'*20)\n",
    "        print('-'*20, f'结果已保存至{result.save_dir}/paper_data.txt...', '-'*20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
